{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7e0485-74ec-4333-9c7a-f55ef4889ec2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082b7886-1c0f-40a9-94a8-2749bcc7a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_group_map = {\n",    
    "     'F': 'F'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb593d5-7347-4de0-9036-7ed900e82c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def resample_interpolation(ts, fs_in, fs_out):\n",
    "    if fs_out == fs_in:\n",
    "        return ts\n",
    "    else:\n",
    "        x_old = np.linspace(0, 1, num=len(ts), endpoint=True)\n",
    "        x_new = np.linspace(0, 1, num=fs_out, endpoint=True)\n",
    "        return np.interp(x_new, x_old, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e343447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def read_records(path):\n",
    "     with open(os.path.join(path, 'RECORDS'), 'r') as fin:\n",
    "         all_record_name = fin.read().split('\\n')\n",
    "     return all_record_name\n",
    "read_records(r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ba17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "\n",
    "sample_record = os.path.join(r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data', '100')\n",
    "sample_annotation = wfdb.rdann(sample_record, 'atr').__dict__\n",
    "sample_data = wfdb.rdsamp(sample_record)\n",
    "\n",
    "#print(len(sample_annotation))\n",
    "# print(sample_annotation['record_name'])\n",
    "# print(sample_annotation['symbol'])\n",
    "sample_annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b22cf8-1ed6-4bd6-8b91-40698a72df46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.145, -0.065],\n",
       "        [-0.145, -0.065],\n",
       "        [-0.145, -0.065],\n",
       "        ...,\n",
       "        [-0.675, -0.365],\n",
       "        [-0.765, -0.335],\n",
       "        [-1.28 ,  0.   ]]),\n",
       " {'fs': 360,\n",
       "  'sig_len': 650000,\n",
       "  'n_sig': 2,\n",
       "  'base_date': None,\n",
       "  'base_time': None,\n",
       "  'units': ['mV', 'mV'],\n",
       "  'sig_name': ['MLII', 'V5'],\n",
       "  'comments': ['69 M 1085 1629 x1', 'Aldomet, Inderal']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(sample_data))\n",
    "# print(sample_data[0])\n",
    "# print(sample_data[1]['sig_len'])\n",
    "# print(sample_data[1]['fs'])\n",
    "# print(sample_data[1]['sig_name'])\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22f71c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2274\n",
      "2274\n",
      "[    18     77    370 ... 649484 649734 649991]\n"
     ]
    }
   ],
   "source": [
    "sample_fs = sample_data[1]['fs']\n",
    "sample_leads = sample_data[1]['sig_name']\n",
    "\n",
    "selected_lead_index = sample_leads.index('MLII')\n",
    "print(selected_lead_index)\n",
    "# selected_lead_index = sample_leads.index('V5')\n",
    "# print(selected_lead_index)\n",
    "\n",
    "sample_lead_data = sample_data[0][:, selected_lead_index]\n",
    "\n",
    "print(len(sample_annotation['symbol']))\n",
    "print(len(sample_annotation['sample']))\n",
    "print(sample_annotation['sample'])\n",
    "#print(sample_annotation['symbol'])\n",
    "\n",
    "sample_index_list = list(sample_annotation['sample'])\n",
    "sample_label_list = sample_annotation['symbol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  2271 * 360\n",
      "label size:  2271\n"
     ]
    }
   ],
   "source": [
    "sample_data = []\n",
    "sample_labels = []\n",
    "\n",
    "for i in range(len(sample_label_list)):\n",
    "    sample_mark = sample_label_list[i]\n",
    "    if sample_mark in label_group_map.keys():\n",
    "        idx_start = sample_index_list[i] - int(sample_fs / 2)\n",
    "        idx_end = sample_index_list[i] + int(sample_fs / 2)\n",
    "        if 0 <= idx_start < len(sample_lead_data) and idx_end <= len(sample_lead_data):\n",
    "            sample_segment = sample_lead_data[idx_start: idx_end]\n",
    "            sample_segment_resampled = resample_interpolation(sample_segment, sample_fs, fs_out=360)\n",
    "            sample_data.append(sample_segment_resampled)\n",
    "            sample_labels.append(label_group_map[sample_mark])\n",
    "\n",
    "print('data size: ', len(sample_data), '*', len(sample_data[0]))\n",
    "print('label size: ', len(sample_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c323433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sample_label_encoder = LabelEncoder()\n",
    "sample_labels_encoded = sample_label_encoder.fit_transform(sample_labels)\n",
    "print(set(sample_labels_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907fcca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_and_preprocess_data(path, valid_lead=['MLII'], fs_out=360):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    with open(os.path.join(path, 'RECORDS'), 'r') as fin:\n",
    "        all_record_name = fin.read().strip().split('\\n')\n",
    "\n",
    "    for record_name in all_record_name:\n",
    "        try:\n",
    "            tmp_ann_res = wfdb.rdann(os.path.join(path, record_name), 'atr')\n",
    "            tmp_data_res = wfdb.rdsamp(os.path.join(path, record_name))\n",
    "        except:\n",
    "            print(f'Error reading {record_name}')\n",
    "            continue\n",
    "\n",
    "        fs = tmp_data_res[1]['fs']\n",
    "        lead_in_data = tmp_data_res[1]['sig_name']\n",
    "\n",
    "        if valid_lead[0] in lead_in_data:\n",
    "            channel = lead_in_data.index(valid_lead[0])\n",
    "            tmp_data = tmp_data_res[0][:, channel]\n",
    "\n",
    "            idx_list = list(tmp_ann_res.sample)\n",
    "            label_list = tmp_ann_res.symbol\n",
    "\n",
    "            for i in range(len(label_list)):\n",
    "                s = label_list[i]\n",
    "                if s in label_group_map.keys():\n",
    "                    idx_start = idx_list[i] - int(fs / 2)\n",
    "                    idx_end = idx_list[i] + int(fs / 2)\n",
    "                    if 0 <= idx_start < len(tmp_data) and idx_end <= len(tmp_data):\n",
    "                        segment = tmp_data[idx_start:idx_end]\n",
    "                        segment_resampled = resample_interpolation(segment, fs, fs_out)\n",
    "                        all_data.append(segment_resampled)\n",
    "                        all_labels.append(label_group_map[s])\n",
    "\n",
    "            print(f'Processed {record_name}, total segments: {len(all_data)}')\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "    return np.array(all_data), all_labels_encoded\n",
    "\n",
    "path = r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data'\n",
    "all_data, all_labels = load_and_preprocess_data(path)\n",
    "print()\n",
    "print(f'Preprocessed data shape: {all_data.shape}')\n",
    "print(f'Preprocessed labels shape: {all_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb2f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 802 instances\n",
      "Class 1: 90075 instances\n",
      "Class 2: 3894 instances\n",
      "Class 3: 3026 instances\n",
      "Class 4: 7229 instances\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f'Class {label}: {count} instances')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9f4ae-8a43-43c1-8351-e227c2c71ba2",
   "metadata": {},
   "source": [
    "## 3.feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d50145-0899-4b9d-99c8-baa7bc5e3c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: (105026, 8)\n",
      "[[-0.30979167  0.16913103  0.94       -0.535       5.09997471 30.91398797\n",
      "  -0.51       44.847425  ]\n",
      " [-0.33238889  0.15355008  0.96       -0.57        5.97456751 41.71478844\n",
      "  -0.555      48.2616    ]\n",
      " [-0.33295833  0.14579737  0.86       -0.645       5.6542518  39.14871475\n",
      "  -0.63       47.562525  ]\n",
      " [-0.33195833  0.13820973  0.82       -0.565       5.6519943  39.4829461\n",
      "  -0.555      46.547375  ]\n",
      " [-0.32575     0.14692399  0.885      -0.545       5.52627975 37.60597187\n",
      "  -0.54       45.9719    ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_features(records):\n",
    "    features = []\n",
    "    for record in records:\n",
    "        mean_val = np.mean(record)\n",
    "        std_val = np.std(record)\n",
    "        max_val = np.max(record)\n",
    "        min_val = np.min(record)\n",
    "        \n",
    "        skewness = skew(record)\n",
    "        kurt = kurtosis(record)\n",
    "        \n",
    "        sorted_neg_values = np.sort(record[record < 0])\n",
    "        second_min_val = sorted_neg_values[1] if len(sorted_neg_values) > 1 else (sorted_neg_values[0] if len(sorted_neg_values) == 1 else np.nan)\n",
    "        \n",
    "        fft_vals = np.fft.fft(record)\n",
    "        power_spectrum = np.mean(np.abs(fft_vals) ** 2)\n",
    "\n",
    "        features.append([mean_val, std_val, max_val, min_val, skewness, kurt, second_min_val, power_spectrum])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "features = extract_features(all_data)\n",
    "\n",
    "print(f'Extracted features shape: {features.shape}')\n",
    "print(features[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82150314-9c1c-4319-9c47-23a3cea982d2",
   "metadata": {},
   "source": [
    "## 4.Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc012e24-07fc-4f83-bb01-0e62470a9ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (84020, 8), Training labels shape: (84020,)\n",
      "Test data shape: (21006, 8), Test labels shape: (21006,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08781fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab6bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3e4a0-96ea-44d0-a19f-1e9778b514bd",
   "metadata": {},
   "source": [
    "## 5.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c2a29dd-57cb-4f1f-b305-6130778395a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model trained successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_ensemble_voting(X_train, y_train):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    \n",
    "    svm_model = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', SVC(probability=True, random_state=44, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    rf_model = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', RandomForestClassifier(random_state=44, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "        ('svm', svm_model),\n",
    "        ('rf', rf_model)], voting='soft')\n",
    "\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    return ensemble_model\n",
    "\n",
    "ensemble_model = train_ensemble_voting(X_train, y_train)\n",
    "\n",
    "print('Ensemble model trained successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb50597-74f7-4926-9b69-d500c2b5d7b4",
   "metadata": {},
   "source": [
    "## 6.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20389f1d-a820-485b-8083-207d32775200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 0.92\n",
      "Recall: 0.59\n",
      "F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
