{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7e0485-74ec-4333-9c7a-f55ef4889ec2",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082b7886-1c0f-40a9-94a8-2749bcc7a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_group_map = {\n",
    "    'N': 'N', 'L': 'N', 'R': 'N', 'V': 'V', 'E': 'V',\n",
    "    'A': 'S', 'j': 'S', 'e': 'S', 'S': 'S', 'a': 'S', 'J': 'S',\n",
    "    '/': 'Q', 'f': 'Q', 'Q': 'Q', 'F': 'F'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fb593d5-7347-4de0-9036-7ed900e82c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def resample_interpolation(ts, fs_in, fs_out):\n",
    "    if fs_out == fs_in:\n",
    "        return ts\n",
    "    else:\n",
    "        x_old = np.linspace(0, 1, num=len(ts), endpoint=True)\n",
    "        x_new = np.linspace(0, 1, num=fs_out, endpoint=True)\n",
    "        return np.interp(x_new, x_old, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e46e29ee-54d7-4952-a85c-dbfa85e5db95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100',\n",
       " '101',\n",
       " '102',\n",
       " '103',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '109',\n",
       " '111',\n",
       " '112',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '119',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '124',\n",
       " '200',\n",
       " '201',\n",
       " '202',\n",
       " '203',\n",
       " '205',\n",
       " '207',\n",
       " '208',\n",
       " '209',\n",
       " '210',\n",
       " '212',\n",
       " '213',\n",
       " '214',\n",
       " '215',\n",
       " '217',\n",
       " '219',\n",
       " '220',\n",
       " '221',\n",
       " '222',\n",
       " '223',\n",
       " '228',\n",
       " '230',\n",
       " '231',\n",
       " '232',\n",
       " '233',\n",
       " '234',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def read_records(path):\n",
    "     with open(os.path.join(path, 'RECORDS'), 'r') as fin:\n",
    "         all_record_name = fin.read().split('\\n')\n",
    "     return all_record_name\n",
    "read_records(r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9345477-208e-4eb2-a3ff-98d1550a3c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'record_name': '100',\n",
       " 'extension': 'atr',\n",
       " 'sample': array([    18,     77,    370, ..., 649484, 649734, 649991], dtype=int64),\n",
       " 'symbol': ['+',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'A',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  'N',\n",
       "  ...],\n",
       " 'subtype': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'chan': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'num': array([0, 0, 0, ..., 0, 0, 0]),\n",
       " 'aux_note': ['(N\\x00',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ...],\n",
       " 'fs': 360,\n",
       " 'label_store': None,\n",
       " 'description': None,\n",
       " 'custom_labels': None,\n",
       " 'contained_labels': None,\n",
       " 'ann_len': 2274}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wfdb\n",
    "\n",
    "sample_record = os.path.join(r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data', '100')\n",
    "sample_annotation = wfdb.rdann(sample_record, 'atr').__dict__\n",
    "sample_data = wfdb.rdsamp(sample_record)\n",
    "\n",
    "#print(len(sample_annotation))\n",
    "# print(sample_annotation['record_name'])\n",
    "# print(sample_annotation['symbol'])\n",
    "sample_annotation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b22cf8-1ed6-4bd6-8b91-40698a72df46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.145, -0.065],\n",
       "        [-0.145, -0.065],\n",
       "        [-0.145, -0.065],\n",
       "        ...,\n",
       "        [-0.675, -0.365],\n",
       "        [-0.765, -0.335],\n",
       "        [-1.28 ,  0.   ]]),\n",
       " {'fs': 360,\n",
       "  'sig_len': 650000,\n",
       "  'n_sig': 2,\n",
       "  'base_date': None,\n",
       "  'base_time': None,\n",
       "  'units': ['mV', 'mV'],\n",
       "  'sig_name': ['MLII', 'V5'],\n",
       "  'comments': ['69 M 1085 1629 x1', 'Aldomet, Inderal']})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(len(sample_data))\n",
    "# print(sample_data[0])\n",
    "# print(sample_data[1]['sig_len'])\n",
    "# print(sample_data[1]['fs'])\n",
    "# print(sample_data[1]['sig_name'])\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22f71c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2274\n",
      "2274\n",
      "[    18     77    370 ... 649484 649734 649991]\n"
     ]
    }
   ],
   "source": [
    "sample_fs = sample_data[1]['fs']\n",
    "sample_leads = sample_data[1]['sig_name']\n",
    "\n",
    "selected_lead_index = sample_leads.index('MLII')\n",
    "print(selected_lead_index)\n",
    "# selected_lead_index = sample_leads.index('V5')\n",
    "# print(selected_lead_index)\n",
    "\n",
    "sample_lead_data = sample_data[0][:, selected_lead_index]\n",
    "\n",
    "print(len(sample_annotation['symbol']))\n",
    "print(len(sample_annotation['sample']))\n",
    "print(sample_annotation['sample'])\n",
    "#print(sample_annotation['symbol'])\n",
    "\n",
    "sample_index_list = list(sample_annotation['sample'])\n",
    "sample_label_list = sample_annotation['symbol']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a45c54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  2271 * 360\n",
      "label size:  2271\n"
     ]
    }
   ],
   "source": [
    "sample_data = []\n",
    "sample_labels = []\n",
    "\n",
    "for i in range(len(sample_label_list)):\n",
    "    sample_mark = sample_label_list[i]\n",
    "    if sample_mark in label_group_map.keys():\n",
    "        idx_start = sample_index_list[i] - int(sample_fs / 2)\n",
    "        idx_end = sample_index_list[i] + int(sample_fs / 2)\n",
    "        if 0 <= idx_start < len(sample_lead_data) and idx_end <= len(sample_lead_data):\n",
    "            sample_segment = sample_lead_data[idx_start: idx_end]\n",
    "            sample_segment_resampled = resample_interpolation(sample_segment, sample_fs, fs_out=360)\n",
    "            sample_data.append(sample_segment_resampled)\n",
    "            sample_labels.append(label_group_map[sample_mark])\n",
    "\n",
    "print('data size: ', len(sample_data), '*', len(sample_data[0]))\n",
    "print('label size: ', len(sample_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c323433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "sample_label_encoder = LabelEncoder()\n",
    "sample_labels_encoded = sample_label_encoder.fit_transform(sample_labels)\n",
    "print(set(sample_labels_encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0f226c9-b742-4d20-8c8c-6015a9d52602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100, total segments: 2271\n",
      "Processed 101, total segments: 4135\n",
      "Processed 103, total segments: 6218\n",
      "Processed 105, total segments: 8790\n",
      "Processed 106, total segments: 10817\n",
      "Processed 107, total segments: 12953\n",
      "Processed 108, total segments: 14715\n",
      "Processed 109, total segments: 17245\n",
      "Processed 111, total segments: 19369\n",
      "Processed 112, total segments: 21906\n",
      "Processed 113, total segments: 23699\n",
      "Processed 114, total segments: 25578\n",
      "Processed 115, total segments: 27529\n",
      "Processed 116, total segments: 29940\n",
      "Processed 117, total segments: 31474\n",
      "Processed 118, total segments: 33751\n",
      "Processed 119, total segments: 35738\n",
      "Processed 121, total segments: 37599\n",
      "Processed 122, total segments: 40073\n",
      "Processed 123, total segments: 41590\n",
      "Processed 124, total segments: 43208\n",
      "Processed 200, total segments: 45808\n",
      "Processed 201, total segments: 47770\n",
      "Processed 202, total segments: 49905\n",
      "Processed 203, total segments: 52884\n",
      "Processed 205, total segments: 55539\n",
      "Processed 207, total segments: 57398\n",
      "Processed 208, total segments: 60351\n",
      "Processed 209, total segments: 63355\n",
      "Processed 210, total segments: 66003\n",
      "Processed 212, total segments: 68750\n",
      "Processed 213, total segments: 71999\n",
      "Processed 214, total segments: 74259\n",
      "Processed 215, total segments: 77620\n",
      "Processed 217, total segments: 79828\n",
      "Processed 219, total segments: 81982\n",
      "Processed 220, total segments: 84028\n",
      "Processed 221, total segments: 86455\n",
      "Processed 222, total segments: 88936\n",
      "Processed 223, total segments: 91540\n",
      "Processed 228, total segments: 93592\n",
      "Processed 230, total segments: 95847\n",
      "Processed 231, total segments: 97417\n",
      "Processed 232, total segments: 99197\n",
      "Processed 233, total segments: 102274\n",
      "Processed 234, total segments: 105026\n",
      "\n",
      "Preprocessed data shape: (105026, 360)\n",
      "Preprocessed labels shape: (105026,)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def load_and_preprocess_data(path, valid_lead=['MLII'], fs_out=360):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    with open(os.path.join(path, 'RECORDS'), 'r') as fin:\n",
    "        all_record_name = fin.read().strip().split('\\n')\n",
    "\n",
    "    for record_name in all_record_name:\n",
    "        try:\n",
    "            tmp_ann_res = wfdb.rdann(os.path.join(path, record_name), 'atr')\n",
    "            tmp_data_res = wfdb.rdsamp(os.path.join(path, record_name))\n",
    "        except:\n",
    "            print(f'Error reading {record_name}')\n",
    "            continue\n",
    "\n",
    "        fs = tmp_data_res[1]['fs']\n",
    "        lead_in_data = tmp_data_res[1]['sig_name']\n",
    "\n",
    "        if valid_lead[0] in lead_in_data:\n",
    "            channel = lead_in_data.index(valid_lead[0])\n",
    "            tmp_data = tmp_data_res[0][:, channel]\n",
    "\n",
    "            idx_list = list(tmp_ann_res.sample)\n",
    "            label_list = tmp_ann_res.symbol\n",
    "\n",
    "            for i in range(len(label_list)):\n",
    "                s = label_list[i]\n",
    "                if s in label_group_map.keys():\n",
    "                    idx_start = idx_list[i] - int(fs / 2)\n",
    "                    idx_end = idx_list[i] + int(fs / 2)\n",
    "                    if 0 <= idx_start < len(tmp_data) and idx_end <= len(tmp_data):\n",
    "                        segment = tmp_data[idx_start:idx_end]\n",
    "                        segment_resampled = resample_interpolation(segment, fs, fs_out)\n",
    "                        all_data.append(segment_resampled)\n",
    "                        all_labels.append(label_group_map[s])\n",
    "\n",
    "            print(f'Processed {record_name}, total segments: {len(all_data)}')\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "    return np.array(all_data), all_labels_encoded\n",
    "\n",
    "path = r'D:\\CodeProjects\\VsCodePythonPro\\MachinelearningClass\\EX5\\mit-bih-arrhythmia-database-1.0.0_data'\n",
    "all_data, all_labels = load_and_preprocess_data(path)\n",
    "print()\n",
    "print(f'Preprocessed data shape: {all_data.shape}')\n",
    "print(f'Preprocessed labels shape: {all_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240c37a6",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb2f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 802 instances\n",
      "Class 1: 90075 instances\n",
      "Class 2: 3894 instances\n",
      "Class 3: 3026 instances\n",
      "Class 4: 7229 instances\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f'Class {label}: {count} instances')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c9f4ae-8a43-43c1-8351-e227c2c71ba2",
   "metadata": {},
   "source": [
    "## 3.feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2d50145-0899-4b9d-99c8-baa7bc5e3c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted features shape: (105026, 8)\n",
      "[[-0.30979167  0.16913103  0.94       -0.535       5.09997471 30.91398797\n",
      "  -0.51       44.847425  ]\n",
      " [-0.33238889  0.15355008  0.96       -0.57        5.97456751 41.71478844\n",
      "  -0.555      48.2616    ]\n",
      " [-0.33295833  0.14579737  0.86       -0.645       5.6542518  39.14871475\n",
      "  -0.63       47.562525  ]\n",
      " [-0.33195833  0.13820973  0.82       -0.565       5.6519943  39.4829461\n",
      "  -0.555      46.547375  ]\n",
      " [-0.32575     0.14692399  0.885      -0.545       5.52627975 37.60597187\n",
      "  -0.54       45.9719    ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_features(records):\n",
    "    features = []\n",
    "    for record in records:\n",
    "        mean_val = np.mean(record)\n",
    "        std_val = np.std(record)\n",
    "        max_val = np.max(record)\n",
    "        min_val = np.min(record)\n",
    "        \n",
    "        skewness = skew(record)\n",
    "        kurt = kurtosis(record)\n",
    "        \n",
    "        sorted_neg_values = np.sort(record[record < 0])\n",
    "        second_min_val = sorted_neg_values[1] if len(sorted_neg_values) > 1 else (sorted_neg_values[0] if len(sorted_neg_values) == 1 else np.nan)\n",
    "        \n",
    "        fft_vals = np.fft.fft(record)\n",
    "        power_spectrum = np.mean(np.abs(fft_vals) ** 2)\n",
    "\n",
    "        features.append([mean_val, std_val, max_val, min_val, skewness, kurt, second_min_val, power_spectrum])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "features = extract_features(all_data)\n",
    "\n",
    "print(f'Extracted features shape: {features.shape}')\n",
    "print(features[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82150314-9c1c-4319-9c47-23a3cea982d2",
   "metadata": {},
   "source": [
    "## 4.Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc012e24-07fc-4f83-bb01-0e62470a9ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (84020, 8), Training labels shape: (84020,)\n",
      "Test data shape: (21006, 8), Test labels shape: (21006,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'Training data shape: {X_train.shape}, Training labels shape: {y_train.shape}')\n",
    "print(f'Test data shape: {X_test.shape}, Test labels shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08781fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab6bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('X_train.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c3e4a0-96ea-44d0-a19f-1e9778b514bd",
   "metadata": {},
   "source": [
    "## 5.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c2a29dd-57cb-4f1f-b305-6130778395a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble model trained successfully\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def train_ensemble_voting(X_train, y_train):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    \n",
    "    svm_model = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', SVC(probability=True, random_state=44, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    rf_model = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('classifier', RandomForestClassifier(random_state=44, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "        ('svm', svm_model),\n",
    "        ('rf', rf_model)], voting='soft')\n",
    "\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    return ensemble_model\n",
    "\n",
    "ensemble_model = train_ensemble_voting(X_train, y_train)\n",
    "\n",
    "print('Ensemble model trained successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb50597-74f7-4926-9b69-d500c2b5d7b4",
   "metadata": {},
   "source": [
    "## 6.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20389f1d-a820-485b-8083-207d32775200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Precision: 0.92\n",
      "Recall: 0.59\n",
      "F1 Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print(f'Precision: {precision:.2f}')\n",
    "    print(f'Recall: {recall:.2f}')\n",
    "    print(f'F1 Score: {f1:.2f}')\n",
    "\n",
    "evaluate_model(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb7b68c",
   "metadata": {},
   "source": [
    " **Question:** \n",
    "\n",
    "**1_ What were the key differences between the approach used in our teaching notebook and the methodology described in the research paper for arrhythmia detection?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1275514",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "in the paper, a larger set of target  was initially explored for model.\n",
    "however, the teaching notebook simplified this by employing the label_group_map to combined these categories.\n",
    "moreover, while the paper applied a combination of Naive Bayes, SVM, and Random Forest ,\n",
    "these same models were selectively implemented in the instructional example. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72258b9d",
   "metadata": {},
   "source": [
    " **Question:**  \n",
    "**2_ Is the model performance in the educational notebook satisfactory? Why or why not?**  \n",
    "If you do not have any ideas, feel free to proceed to the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29857307-0637-4859-8933-3384f2e07a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer here:\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Answer here:\n",
    "\n",
    "low recall and F1 score reflect the model's limited and not performing as well in capturing all relevant instance\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c74073",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73125ca",
   "metadata": {},
   "source": [
    "**Experiment 1:**  \n",
    " After the final cell of `the Preprocessing` section, add a new cell. NumPy has a function called `unique` that can help you get the unique labels and the count of each label in the entire dataset. In this cell, use this function to display the count of each class.  \n",
    " re-run the educational notebook `ECG- Ensemble Learning.ipynb.` This time, ensure that both the Recall and F1_score metrics are also displayed along with the other evaluation metrics.  \n",
    " Save the notebook for this experiment as `Experiment 1.ipynb`.  \n",
    " In the next cell, enter the model's performance results using the four evaluation metrics discussed.  \n",
    " Then, revisit and answer Question 2 based on the new results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa540a8d",
   "metadata": {},
   "source": [
    " **Note:**  \n",
    "NumPy provides two simple commands for saving and loading data in `.npy` format. These two commands allow us to efficiently save and load arrays like `X_train`, `X_test`, `y_train`, and `y_test`.  \n",
    "Since we will need to run the code multiple times throughout this notebook, to save time, we will store the processed data, comment out the preprocessing section, and then load the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377d89d-f478-4485-ba6a-a59079768b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:   \\nPrecision:   \\nRecall:   \\nF1 score: \\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Accuracy: 0.93\n",
    "Precision: 0.85\n",
    "Recall: 0.56\n",
    "F1 Score: 0.60\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821d21d",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a7d8f",
   "metadata": {},
   "source": [
    "**Experiment 2:**  \n",
    " One of the issues observed in the educational notebook was the imbalance in the number of samples for each class. To address this problem, both the `SVC` and `RandomForestClassifier` models have a parameter called `class_weight`. By setting this parameter to `'balanced'`, the models automatically assign higher weights to classes with fewer samples and lower weights to classes with more samples.   \n",
    " Re-run the educational notebook, but this time, set the `class_weight` parameter to `'balanced'` for both the `SVC` and `RandomForestClassifier` models. After training the models with this configuration, calculate and display the values for all four evaluation metrics.  \n",
    " Save the notebook for this experiment as `Experiment 2.ipynb`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d246e1-470f-40cd-bbcd-22d3d61d884b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:   \\nPrecision:   \\nRecall:   \\nF1 score: \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Accuracy: 0.93\n",
    "Precision: 0.85\n",
    "Recall: 0.58\n",
    "F1 Score: 0.63\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd808dc",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07454f37",
   "metadata": {},
   "source": [
    " **Question:**  \n",
    "**3_ Was there any improvement in the evaluation metrics?**  \n",
    "**4_ By studying the documentation of models in scikit-learn, explain how the class weights are calculated when class_weight= 'balanced' is used for balancing the models. What formula is used to determine the weight of each class?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50755308-b559-415b-828d-4039e3b2d5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nAnswer here:\\n3)\\nsmall improvement noted.\\n\\n4)\\nClass weight:\\ni = n_samples / (n_classes * n_samples_i)\\n\\nn_samples is the dataset's total sample count.\\nn_classes represent number of unique categories\\nn_samples_i denotes the sample count for each class.  \\n\\nthis approach emphasizes categories with fewer samples, encouraging the model to address less-represented classes more effectively\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Answer here:\n",
    "3)\n",
    "small improvement noted.\n",
    "\n",
    "4)\n",
    "Class weight:\n",
    "i = n_samples / (n_classes * n_samples_i)\n",
    "\n",
    "n_samples is the dataset's total sample count.\n",
    "n_classes represent number of unique categories\n",
    "n_samples_i denotes the sample count for each class.  \n",
    "\n",
    "this approach emphasizes categories with fewer samples, encouraging the model to address less-represented classes more effectively\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31832032",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db76a57-10bc-4530-bba0-2667a1e8589a",
   "metadata": {},
   "source": [
    "**Experiment 3:**  \n",
    " Add the four additional features, `Skewness of the signal`, `Kurtosis of the signal`, `Second peak negative value`, and `Power spectrum of the signal`, as mentioned in the article to the existing features (`Mean absolute value of the signal`, `Standard deviation`, `Peak positive value`, `Peak negative value`).   \n",
    " Re-run the educational notebook using this set of 8 features with balanced class weights.  \n",
    " Save the notebook for this experiment as `Experiment 3.ipynb`.  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875e5d79-d9a7-4e50-935a-9b85dfeb0995",
   "metadata": {},
   "source": [
    " **Note:**  \n",
    "Use the NumPy and SciPy libraries to calculate the additional four features.  \n",
    "SciPy is a library in Python that provides fundamental algorithms for scientific computing, enabling efficient numerical and scientific operations.  \n",
    "[SciPy](https://scipy.org)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19f27f5-f3a5-493b-8acf-e2402d27e207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy:   \\nPrecision:   \\nRecall:   \\nF1 score: \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Accuracy: 0.94\n",
    "Precision: 0.92\n",
    "Recall: 0.59\n",
    "F1 Score: 0.66 \n",
    " \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3e087d-a5b0-4407-87e8-07b75f06bb95",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
